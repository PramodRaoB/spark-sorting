import org.apache.spark.SparkContext
import org.apache.spark.SparkConf
import org.apache.spark.storage.StorageLevel

object exp1_rdd {
  def main(args: Array[String]) {
    val sparkConf = new SparkConf().setAppName("exp0_rdd_v2").set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
    val sc = SparkContext.getOrCreate(sparkConf)

    val input_file = "hdfs://rce:9001/user/hdfs/data.sam"

    case class kv_pair(_1: Int, _2: String)

    val lines = sc.textFile(input_file)
    val filtered_lines = lines.filter(line => line.startsWith("@") == false)
    val rdd = filtered_lines.map(x => (x.split('\t')(3).toInt, x)).persist(StorageLevel.MEMORY_ONLY_SER)

    val final_rdd = rdd.sortByKey()
    print(final_rdd.count())
    sc.stop()
  }
}
